"""
Static Site Builder Core Logic
- Ported from Dashboard/builder.py
- Builds index.html, trade.html
"""

import json
import shutil
from datetime import datetime
from pathlib import Path

import markdown
from jinja2 import Environment, FileSystemLoader

from core.config import PROJECT_ROOT
from core.logger import get_logger

log = get_logger("site_builder.core")

# Paths
MODULE_DIR = PROJECT_ROOT / "modules" / "site_builder"
TEMPLATES_DIR = MODULE_DIR / "templates"
STATIC_DIR = MODULE_DIR / "static"
DOCS_DIR = PROJECT_ROOT / "docs"

# Data Paths (Unified)
DATA_DIR = PROJECT_ROOT / "data"
NEWS_DATA_DIR = DATA_DIR / "news"
NEWS_DATA_DIR = DATA_DIR / "news"
TRADE_DATA_FILE = DATA_DIR / "trade" / "status.json"
MICROGPT_DATA_FILE = DATA_DIR / "microgpt" / "trace.json"


def load_latest_news():
    """Loads the most recent news JSON from data/news/."""
    # Recursive search: data/news/**/*.json
    if not NEWS_DATA_DIR.exists():
        return None

    news_files = list(NEWS_DATA_DIR.rglob("*.json"))

    if not news_files:
        return None

    all_news = []
    for f_path in news_files:
        try:
            with open(f_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'created_at' in data:
                    all_news.append(data)
        except Exception as e:
            log.warning(f"Error loading news {f_path}: {e}")
            continue

    if not all_news:
        return None

    # Sort by created_at descending
    all_news.sort(key=lambda x: x.get('created_at', ''), reverse=True)
    return all_news[0]



def load_recent_news_list(limit=7):
    """Loads recent news metadata for sidebar navigation."""
    if not NEWS_DATA_DIR.exists():
        return []

    news_items = []
    # Scan both morning and evening directories
    for mode in ['morning', 'evening']:
        mode_dir = NEWS_DATA_DIR / mode
        if not mode_dir.exists():
            continue

        for f_path in mode_dir.glob("*.json"):
            try:
                with open(f_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Extract minimal info needed for link
                    item = {
                        'date': f_path.stem,  # YYYYMMDD
                        'mode': mode,
                        'title': data.get('video_title', 'News Briefing'),
                        'created_at': data.get('created_at', '')
                    }
                    news_items.append(item)
            except Exception as e:
                log.warning(f"Error loading news metadata {f_path}: {e}")
                continue

    # Sort by created_at descending (or date if created_at missing)
    news_items.sort(key=lambda x: x.get('created_at', x['date']), reverse=True)
    return news_items[:limit]


def load_trade_status():
    """Loads the latest trade status from data/trade/status.json."""
    if TRADE_DATA_FILE.exists():
        try:
            with open(TRADE_DATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            log.error(f"Error loading trade status: {e}")
    return None


def map_reason_code(log_entry):
    """Maps technical reason codes to user-friendly Korean explanations."""
    code = log_entry.get('reason_code', log_entry.get('reason', '')).upper()
    confidence = log_entry.get('confidence', 0)

    # Custom mapping dictionary with detailed explanations
    mapping = {
        "TREND_ALIGNMENT": ("ğŸ“‰ í˜„ì¬ ê°€ê²©ì´ ì¥ê¸° ì´ë™í‰ê· ì„ (60ì¼ì„ ) ì•„ë˜ì— ìˆì–´ í•˜ë½ì„¸ê°€ ê°•í•©ë‹ˆë‹¤. ì•ˆì „ì„ ìœ„í•´ ë§¤ìˆ˜ë¥¼ ë³´ë¥˜í–ˆìŠµë‹ˆë‹¤."),
        "VOLATILITY_FILTER": ("ğŸŒªï¸ ì‹œì¥ì˜ ë³€ë™ì„±ì´ ë„ˆë¬´ ì ê±°ë‚˜ ë°˜ëŒ€ë¡œ ë„ˆë¬´ ê·¹ì‹¬í•©ë‹ˆë‹¤. ì˜ˆì¸¡ì´ ì–´ë ¤ì›Œ ì§„ì…í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
        "LOW_CONFIDENCE": (f"ğŸ¤” AIì˜ ë¶„ì„ ê²°ê³¼, ìƒìŠ¹ í™•ì‹ ë„ê°€ ê¸°ì¤€ì¹˜(0.55)ë³´ë‹¤ ë‚®ì€ {confidence:.2f}ì…ë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê°•í•œ ì‹œê·¸ë„ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."),
        "MAX_COINS_REACHED": ("ğŸš« ì´ë¯¸ ê³µê²©ì ìœ¼ë¡œ íˆ¬ìí•˜ì—¬ ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ìˆ˜ìµ ì‹¤í˜„ í›„ ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ë…¸ë¦¬ê² ìŠµë‹ˆë‹¤."),
        "ASSET_ALLOCATION": ("âš ï¸ í•œ ì¢…ëª©ì— ì§‘ì¤‘ íˆ¬ìí•  ìˆ˜ ìˆëŠ” ê³µê²©ì  í•œê³„ì¹˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€ ë§¤ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤."),
        "CONSECUTIVE_LOSS_PROTECTION": ("ğŸ›¡ï¸ ìµœê·¼ ì—°ì†ìœ¼ë¡œ ì†ì‹¤ì´ ë°œìƒí•˜ì—¬ 'ì¿¨ë‹¤ìš´' ì¤‘ì…ë‹ˆë‹¤. ì‹œì¥ì´ ì•ˆì •ë  ë•Œê¹Œì§€ ê´€ë§í•©ë‹ˆë‹¤."),
        "LOSS_CUT": ("âœ‚ï¸ ì†ì ˆë§¤(-5%) ë¼ì¸ ë„ë‹¬! ì¶”ê°€ í•˜ë½ì„ ë§‰ê¸° ìœ„í•´ ì¹¼ê°™ì´ ê¸°ê³„ì  ë§¤ë„ë¥¼ ì§‘í–‰í•©ë‹ˆë‹¤."),
        "TAKE_PROFIT": ("ğŸ’° ìˆ˜ìµ ëª©í‘œ(+5%) ë„ë‹¬! ìš•ì‹¬ ë¶€ë¦¬ì§€ ì•Šê³  ì´ìµì„ ì±™ê¹ë‹ˆë‹¤."),
        "STRUCTURE_UNCLEAR": ("ğŸ¤· ì°¨íŠ¸ ë°©í–¥ì„±ì´ ì•„ì§ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„£ë¶ˆë¦¬ ë“¤ì–´ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤."),
        "API_ERROR": ("âš ï¸ ì¼ì‹œì ì¸ ì‹œìŠ¤í…œ/í†µì‹  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•ˆì „ì„ ìœ„í•´ ì´ë²ˆ í„´ì€ ê±´ë„ˆëœë‹ˆë‹¤."),
        "CAPITAL_PRESERVATION": ("ğŸ›¡ï¸ ìë³¸ì„ ì§€í‚¤ëŠ” ê²ƒì´ ë¨¼ì €ì…ë‹ˆë‹¤. í™•ì‹¤í•œ íƒ€ì ì´ ì˜¬ ë•Œê¹Œì§€ ì›…í¬ë¦½ë‹ˆë‹¤."),
        "UNCLEAR_TREND": ("â“ ì¶”ì„¸ê°€ ë§¤ìš° ëª¨í˜¸í•©ë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„± ë¦¬ìŠ¤í¬ë¥¼ í”¼í•˜ê² ìŠµë‹ˆë‹¤."),
        "LOW_CONFIDENCE_AND_UNCLEAR_TREND": ("ğŸ¤” í™•ì‹ ë„ ì—†ê³  ì¶”ì„¸ë„ ì—†ìŠµë‹ˆë‹¤. ì§„ì… ë¶ˆê°€ íŒë‹¨."),
        "BEARISH_MOMENTUM_INDICATORS": ("ğŸ“‰ ë³´ì¡°ì§€í‘œê°€ ê°•ë ¥í•œ í•˜ë½ ì‹œê·¸ë„ì„ ë¿œê³  ìˆìŠµë‹ˆë‹¤."),
        "PRICE_BELOW_MAS": ("ğŸ“‰ ì—­ë°°ì—´(ì´í‰ì„  ì•„ë˜) ìƒíƒœì…ë‹ˆë‹¤. ë¬´ê²ê²Œ ì§“ëˆŒë ¤ ìƒìŠ¹ì´ í˜ë“­ë‹ˆë‹¤."),
        "STRONG_MOMENTUM": ("ğŸ”¥ ê°•ë ¥í•œ íŒŒë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ìƒìŠ¹ ëª¨ë©˜í…€ì„ íƒ€ê³  ê³µê²©ì ì¸ ë§¤ìˆ˜ì— ë“¤ì–´ê°‘ë‹ˆë‹¤."),
        "BREAKOUT": ("ğŸš€ ì£¼ìš” ì €í•­ì„ ì„ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤. ìŠˆíŒ… êµ¬ê°„ì„ ë…¸ë¦¬ê³  ê³¼ê°í•˜ê²Œ ì§„ì…í•©ë‹ˆë‹¤."),
        "DIP_BUY": ("ğŸ“‰ ì˜ë¯¸ ìˆëŠ” ì§€ì§€ êµ¬ê°„ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ë°˜ë“±ì„ ë…¸ë¦¬ê³  ì €ì  ë§¤ìˆ˜ì— ë‚˜ì„­ë‹ˆë‹¤."),
        "REVERSAL_SIGNAL": ("ğŸ”„ í•˜ë½ íŒŒë™ì´ ëë‚˜ê³  ìœ„ë¡œ ê³ ê°œë¥¼ ë“­ë‹ˆë‹¤. ì¶”ì„¸ ì „í™˜ì˜ ì´ˆì…ì—ì„œ ì„ ì·¨ë§¤í•©ë‹ˆë‹¤."),
        "POTENTIAL_REVERSAL": ("ğŸ”„ ì¶”ì„¸ê°€ ë„ëŠ” ëŠë‚Œì…ë‹ˆë‹¤. ë°”ë‹¥ê¶Œì—ì„œì˜ ê¸°íšŒë¥¼ ë‚šì•„ì±„ê² ìŠµë‹ˆë‹¤."),
        "REVERSAL_DIVERGENCE": ("ğŸ“ˆ ê°€ê²©ì€ ë¹ ì§€ëŠ”ë° RSIëŠ” ì˜¤íˆë ¤ ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤(ìƒìŠ¹ ë‹¤ì´ë²„ì „ìŠ¤). ë°˜ë“±ì´ ë¨¸ì§€ì•Šì•˜ìŠµë‹ˆë‹¤."),
        "REVERSAL_CANDIDATE": ("â¸ï¸ ì¶”ì„¸ ì „í™˜ì˜ ëƒ„ìƒˆëŠ” ë‚˜ì§€ë§Œ, ì•„ì§ ë§ˆì§€ë§‰ í™•ì‹  ë„ì¥ì´ ì°íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
        "FAVORABLE_MOMENTUM": ("ğŸ ë§¤ìˆ˜ì„¸ê°€ ë¶™ê³  ìˆìŠµë‹ˆë‹¤. ë‹¬ë¦¬ëŠ” ë§ì— ì˜¬ë¼íƒ€ ë‹¨ê¸° ìˆ˜ìµì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤."),
        "RSI_FILTER": ("ğŸ“Š ë³´ì¡°ì§€í‘œ í•„í„°ì—ì„œ ë³´ìˆ˜ì ì¸ ì‹ í˜¸ê°€ ë‚˜ì™€ ì§„ì…í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."),
        "RSI_FILTER_NOT_MET": ("ğŸ“Š ë‹¨ê¸° ê¸‰ë°˜ë“± ì¡°ê±´ì— ë¶€í•©í•˜ì§€ ì•Šì•„ ë§¤ìˆ˜ë¥¼ ë³´ë¥˜í•©ë‹ˆë‹¤."),
        "RSI_FILTER_CONDITION_NOT_MET": ("ğŸ“Š í˜„ì¬ ì§€í‘œ ìƒíƒœë¡œëŠ” ìˆ˜ìµì„ ë‚¼ ë§Œí•œ íƒ€ì ì´ ì•„ë‹™ë‹ˆë‹¤."),
        "RSI_FILTER_NO_BUY_SIGNAL": ("ğŸ“Š RSI ìƒ ëšœë ·í•œ ë§¤ìˆ˜ ì‹œê·¸ë„ì´ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
        "RSI_FILTER_OVERBOUGHT": ("ğŸ“ˆ ê³¼ë§¤ìˆ˜ êµ¬ê°„(RSI Overbought)ì…ë‹ˆë‹¤. ì¶”ê²© ë§¤ìˆ˜ëŠ” ìì œí•©ë‹ˆë‹¤."),
        "RSI_OVERBOUGHT": ("ğŸ“ˆ RSIê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤. ë‹¨ê¸° ê³ ì ì¼ ìˆ˜ ìˆì–´ ì§„ì…í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."),
        "RSI_FILTER_NO_ENTRY": ("ğŸ“Š ì¢…í•©ì ì¸ RSI í•„í„° ê²°ê³¼, ì§„ì…í•˜ê¸°ì— ë¶€ì ì ˆí•œ íƒ€ì ì…ë‹ˆë‹¤."),
        "AWAITING_REVERSAL_CONFIRMATION": ("â³ ë°˜ë“±ì˜ ì¡°ì§ì€ ë³´ì´ë‚˜, í™•ì‹¤í•œ ì¶”ì„¸ ì „í™˜ ì‹ í˜¸ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤."),
        "OVERSOLD_BOUNCE_MONITORING": ("ğŸ‘€ ê³¼ë§¤ë„(Oversold) êµ¬ê°„ì…ë‹ˆë‹¤. ë°˜ë“±(Bounce) ì‹œê·¸ë„ ë°œìƒì„ ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§ ì¤‘ì…ë‹ˆë‹¤."),
        "OVERSOLD_HOLDING_FOR_REBOUND": ("ğŸ§˜â€â™‚ï¸ ê³¼ë§¤ë„ ìƒíƒœì´ë¯€ë¡œ ê¸°ìˆ ì  ë°˜ë“±(Rebound) í­ì´ í´ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ì–´ í™€ë”©í•©ë‹ˆë‹¤."),
        "TRAILING_STOP_TRIGGERED": ("ğŸ† ìµœê³ ì  ëŒ€ë¹„ 2% í•˜ë½ ë°œìƒ! íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ì„ ì‘ë™ì‹œì¼œ ìˆ˜ìµì„ êµ³í™ë‹ˆë‹¤."),
        "LET_PROFIT_RUN": ("ğŸƒâ€â™‚ï¸ ì•„ì§ ìƒìŠ¹ ì¶”ì„¸ê°€ êº¾ì´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìˆ˜ìµì„ ëê¹Œì§€ ëŒê³  ê°€ê¸° ìœ„í•´ ë§¤ë„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."),
        "OPPORTUNITY_SWAP": ("ğŸ”„ ê¸°íšŒë¹„ìš© ê·¹ëŒ€í™”! ë¶€ì§„í•œ ì¢…ëª©ì„ ë§¤ë„í•˜ê³  í›¨ì”¬ ë” ê°•ë ¥í•œ ìƒìŠ¹ ëª¨ë¸ë¡œ ê°•ì œ ìŠ¤ìœ„ì¹­í•©ë‹ˆë‹¤.")
    }

    msg_parts = []
    for part in code.split('|'):
        part = part.strip()
        msg_parts.append(f"<li>{mapping.get(part, part)}</li>")

    explanation =f"<ul class='list-disc pl-5 space-y-1 mt-1'>{''.join(msg_parts)}</ul>"

    log_entry['reason_mapped'] = explanation
    return log_entry



def load_microgpt_data():
    """Loads the latest microgpt trace from data/microgpt/trace.json."""
    if MICROGPT_DATA_FILE.exists():
        try:
            with open(MICROGPT_DATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            log.error(f"Error loading microgpt data: {e}")
    return None


def build_trade_page(output_dir, context):
    """Builds the dedicated trading status page."""

    # Process logs to map reasons
    if context.get('trade') and 'recent_trades' in context['trade']:
        # Create a copy/map to avoid modifying original if needed, but here modifying in place is fine or map
        # map_reason_code modifies dict in place and returns it
        context['trade']['recent_trades'] = [
            map_reason_code(log_item) for log_item in context['trade']['recent_trades']
        ]

    # Group trades by ticker
    grouped_trades = {}
    if context.get('trade') and 'recent_trades' in context['trade']:
        for log_entry in context['trade']['recent_trades']:
            ticker = log_entry.get('ticker', 'Unknown')
            if ticker not in grouped_trades:
                grouped_trades[ticker] = []
            grouped_trades[ticker].append(log_entry)

    context['grouped_trades'] = grouped_trades

    env = Environment(loader=FileSystemLoader(str(TEMPLATES_DIR)))
    template = env.get_template('trade.html')
    output = template.render(context)

    with open(output_dir / 'index.html', 'w', encoding='utf-8') as f:
        f.write(output)
    log.info("[OK] Built crypto_trader/index.html")


def build_microgpt_page(output_dir, context):
    """Builds the microgpt visualization page."""
    env = Environment(loader=FileSystemLoader(str(TEMPLATES_DIR)))
    template = env.get_template('microgpt.html')
    output = template.render(context)

    # Output to docs/microgpt/index.html
    microgpt_dir = output_dir / "microgpt"
    microgpt_dir.mkdir(parents=True, exist_ok=True)
    
    with open(microgpt_dir / 'index.html', 'w', encoding='utf-8') as f:
        f.write(output)
    log.info("[OK] Built microgpt/index.html")


def build(output_dir=None):
    """Main build function."""
    if output_dir is None:
        output_dir = DOCS_DIR
    else:
        output_dir = Path(output_dir)

    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. Load Data
    news_data = load_latest_news()
    recent_news = load_recent_news_list()  # Fetch sidebar list
    trade_data = load_trade_status()
    microgpt_data = load_microgpt_data()

    context = {
        'news': news_data,
        'recent_news': recent_news,  # Pass to template
        'trade': trade_data,
        'microgpt': microgpt_data,
        'generated_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'summary_html': markdown.markdown(news_data.get('web_report', '')) if news_data else None,
        'coin_names': {
            "KRW-BTC": "ë¹„íŠ¸ì½”ì¸",
            "KRW-ETH": "ì´ë”ë¦¬ì›€",
            "KRW-XRP": "ë¦¬í”Œ",
            "KRW-SOL": "ì†”ë¼ë‚˜",
            "KRW-AVAX": "ì•„ë°œë€ì²´",
            "KRW-DOGE": "ë„ì§€ì½”ì¸"
        }
    }

    # 2. Render Dashboard (index.html)
    env = Environment(loader=FileSystemLoader(str(TEMPLATES_DIR)))
    template = env.get_template('dashboard.html')
    output_html = template.render(context)

    with open(output_dir / 'index.html', 'w', encoding='utf-8') as f:
        f.write(output_html)
    log.info(f"[OK] Built index.html at {output_dir}")

    # 3. Render Trade Page
    # Output to docs/crypto_trader/index.html
    if trade_data:
        trade_dir = output_dir / "crypto_trader"
        trade_dir.mkdir(parents=True, exist_ok=True)
        build_trade_page(trade_dir, context)

    # 4. Built MicroGPT Page - Always build as it is client-side now
    build_microgpt_page(output_dir, context)

    # 5. Copy Static Files
    if STATIC_DIR.exists():
        static_dst = output_dir / 'static'
        if static_dst.exists():
            shutil.rmtree(static_dst)
        shutil.copytree(STATIC_DIR, static_dst)
        log.info(f"[OK] Static files copied to {static_dst}")
