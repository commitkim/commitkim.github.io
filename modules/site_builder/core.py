"""
Static Site Builder Core Logic
- Ported from Dashboard/builder.py
- Builds index.html, trade.html
"""

import json
import shutil
from datetime import datetime
from pathlib import Path

import markdown
from jinja2 import Environment, FileSystemLoader

from core.config import PROJECT_ROOT
from core.logger import get_logger

log = get_logger("site_builder.core")

# Paths
MODULE_DIR = PROJECT_ROOT / "modules" / "site_builder"
TEMPLATES_DIR = MODULE_DIR / "templates"
STATIC_DIR = MODULE_DIR / "static"
DOCS_DIR = PROJECT_ROOT / "docs"

# Data Paths (Unified)
DATA_DIR = PROJECT_ROOT / "data"
NEWS_DATA_DIR = DATA_DIR / "news"
TRADE_DATA_FILE = DATA_DIR / "trade" / "status.json"


def load_latest_news():
    """Loads the most recent news JSON from data/news/."""
    # Recursive search: data/news/**/*.json
    if not NEWS_DATA_DIR.exists():
        return None

    news_files = list(NEWS_DATA_DIR.rglob("*.json"))

    if not news_files:
        return None

    all_news = []
    for f_path in news_files:
        try:
            with open(f_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'created_at' in data:
                    all_news.append(data)
        except Exception as e:
            log.warning(f"Error loading news {f_path}: {e}")
            continue

    if not all_news:
        return None

    # Sort by created_at descending
    all_news.sort(key=lambda x: x.get('created_at', ''), reverse=True)
    return all_news[0]



def load_recent_news_list(limit=7):
    """Loads recent news metadata for sidebar navigation."""
    if not NEWS_DATA_DIR.exists():
        return []

    news_items = []
    # Scan both morning and evening directories
    for mode in ['morning', 'evening']:
        mode_dir = NEWS_DATA_DIR / mode
        if not mode_dir.exists():
            continue

        for f_path in mode_dir.glob("*.json"):
            try:
                with open(f_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Extract minimal info needed for link
                    item = {
                        'date': f_path.stem,  # YYYYMMDD
                        'mode': mode,
                        'title': data.get('video_title', 'News Briefing'),
                        'created_at': data.get('created_at', '')
                    }
                    news_items.append(item)
            except Exception as e:
                log.warning(f"Error loading news metadata {f_path}: {e}")
                continue

    # Sort by created_at descending (or date if created_at missing)
    news_items.sort(key=lambda x: x.get('created_at', x['date']), reverse=True)
    return news_items[:limit]


def load_trade_status():
    """Loads the latest trade status from data/trade/status.json."""
    if TRADE_DATA_FILE.exists():
        try:
            with open(TRADE_DATA_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            log.error(f"Error loading trade status: {e}")
    return None


def map_reason_code(log_entry):
    """Maps technical reason codes to user-friendly Korean explanations."""
    code = log_entry.get('reason_code', log_entry.get('reason', '')).upper()
    confidence = log_entry.get('confidence', 0)

    # Custom mapping dictionary with detailed explanations
    mapping = {
        "TREND_ALIGNMENT": ("ğŸ“‰ í˜„ì¬ ê°€ê²©ì´ ì¥ê¸° ì´ë™í‰ê· ì„ (60ì¼ì„ ) ì•„ë˜ì— ìˆì–´ í•˜ë½ì„¸ê°€ ê°•í•©ë‹ˆë‹¤. "
                            "ì•ˆì „ì„ ìœ„í•´ ë§¤ìˆ˜ë¥¼ ë³´ë¥˜í–ˆìŠµë‹ˆë‹¤."),
        "VOLATILITY_FILTER": ("ğŸŒªï¸ ì‹œì¥ì˜ ë³€ë™ì„±ì´ ë„ˆë¬´ ì ê±°ë‚˜ ë°˜ëŒ€ë¡œ ë„ˆë¬´ ê·¹ì‹¬í•©ë‹ˆë‹¤. "
                              "ì˜ˆì¸¡ì´ ì–´ë ¤ì›Œ ì§„ì…í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."),
        "LOW_CONFIDENCE": (f"ğŸ¤” AIì˜ ë¶„ì„ ê²°ê³¼, ìƒìŠ¹ í™•ì‹ ë„ê°€ ê¸°ì¤€ì¹˜(0.65)ë³´ë‹¤ ë‚®ì€ {confidence:.2f}ì…ë‹ˆë‹¤. "
                           "ë” í™•ì‹¤í•œ ê¸°íšŒë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤." if confidence < 0.65 else
                           f"ğŸ¤” ìƒìŠ¹ í™•ì‹ ë„ëŠ” {confidence:.2f}ì´ë‚˜, ë‹¤ë¥¸ ìœ„í—˜ ìš”ì¸ìœ¼ë¡œ ì¸í•´ ê´€ë§í•©ë‹ˆë‹¤."),
        "MAX_COINS_REACHED": ("ğŸš« ì´ë¯¸ ìµœëŒ€ ë³´ìœ  ì¢…ëª© ìˆ˜(3ê°œ)ë¥¼ ì±„ì› ìŠµë‹ˆë‹¤. "
                              "ìƒˆë¡œìš´ ì¢…ëª©ì„ ë§¤ìˆ˜í•˜ë ¤ë©´ ê¸°ì¡´ ì¢…ëª©ì´ ë§¤ë„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."),
        "ASSET_ALLOCATION": ("âš ï¸ í•œ ì¢…ëª©ì— ë‹´ì„ ìˆ˜ ìˆëŠ” ìµœëŒ€ ë¹„ì¤‘(30%)ì„ ì´ˆê³¼í•˜ê²Œ ë©ë‹ˆë‹¤. "
                             "ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€ ë§¤ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤."),
        "CONSECUTIVE_LOSS_PROTECTION": ("ğŸ›¡ï¸ ìµœê·¼ ì—°ì†ìœ¼ë¡œ ì†ì‹¤ì´ ë°œìƒí•˜ì—¬ 'ì¿¨ë‹¤ìš´' ì¤‘ì…ë‹ˆë‹¤. "
                                        "ì ì‹œ ë¨¸ë¦¬ë¥¼ ì‹íˆë©° ì‹œì¥ì„ ê´€ë§í•©ë‹ˆë‹¤."),
        "LOSS_CUT": ("âœ‚ï¸ ì•„ì‰½ì§€ë§Œ ì†ì ˆë§¤ ë¼ì¸(-3%)ì„ ê±´ë“œë ¸ìŠµë‹ˆë‹¤. "
                     "ë” í° ì†ì‹¤ì„ ë§‰ê¸° ìœ„í•´ ì›ì¹™ëŒ€ë¡œ ë§¤ë„í•˜ì—¬ ìë³¸ì„ ì§€í‚µë‹ˆë‹¤."),
        "TAKE_PROFIT": ("ğŸ’° ëª©í‘œ ìˆ˜ìµë¥ (+5%)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤! "
                        "ìš•ì‹¬ë¶€ë¦¬ì§€ ì•Šê³  ìˆ˜ìµì„ í™•ì • ì§€ì–´ ì£¼ë¨¸ë‹ˆì— ë„£ìŠµë‹ˆë‹¤."),
        "STRUCTURE_UNCLEAR": ("ğŸ¤· ì°¨íŠ¸ì˜ íë¦„ì´ ìœ„ì¸ì§€ ì•„ë˜ì¸ì§€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                              "ë°©í–¥ì´ ê²°ì •ë  ë•Œê¹Œì§€ ì§€ì¼œë³´ëŠ” ê²Œ ì¢‹ê² ìŠµë‹ˆë‹¤."),
        "API_ERROR": ("âš ï¸ ì¼ì‹œì ì¸ ì‹œìŠ¤í…œ/í†µì‹  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
                      "ì•ˆì „ì„ ìœ„í•´ ì´ë²ˆ í„´ì€ ê±´ë„ˆëœë‹ˆë‹¤."),
        "CAPITAL_PRESERVATION": ("ğŸ’° ì§€ê¸ˆì€ ëˆì„ ë²„ëŠ” ê²ƒë³´ë‹¤ ì§€í‚¤ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•œ ì‹œê¸°ì…ë‹ˆë‹¤. "
                                 "ë¬´ë¦¬í•˜ì§€ ì•Šê³  í˜„ê¸ˆì„ ë³´ìœ í•©ë‹ˆë‹¤."),
        "UNCLEAR_TREND": ("â“ ìƒìŠ¹ì¥ì¸ì§€ í•˜ë½ì¥ì¸ì§€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                          "ì• ë§¤í•  ë• ì‰¬ì–´ê°€ëŠ” ê²ƒì´ ìƒì±…ì…ë‹ˆë‹¤."),
        "LOW_CONFIDENCE_AND_UNCLEAR_TREND": ("ğŸ¤” í™•ì‹ ë„ ë¶€ì¡±í•˜ê³  ì¶”ì„¸ë„ ì• ë§¤í•©ë‹ˆë‹¤. "
                                             "ì´ëŸ´ ë•Œ ë§¤ìˆ˜í•˜ë©´ ë¬¼ë¦¬ê¸° ì‰½ìŠµë‹ˆë‹¤."),
        "BEARISH_MOMENTUM_INDICATORS": ("ğŸ“‰ ë³´ì¡°ì§€í‘œ(MACD, RSI)ê°€ í•˜ë½ì„ ê°€ë¦¬í‚¤ê³  ìˆìŠµë‹ˆë‹¤. "
                                        "ë§¤ìˆ˜í•˜ê¸°ì—” í˜ì´ ë¹ ì ¸ ë³´ì…ë‹ˆë‹¤."),
        "PRICE_BELOW_MAS": ("ğŸ“‰ ê°€ê²©ì´ ì£¼ìš” ì´ë™í‰ê· ì„  ì•„ë˜ë¡œ ì²˜ì ¸ ìˆìŠµë‹ˆë‹¤. "
                            "ìƒìŠ¹ ì¶”ì„¸ë¡œ ëŒì•„ì„¤ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."),
        "RSI_OVERSOLD_BB_LOWER_BOUNCE": ("ğŸ“‰ RSIê°€ ê³¼ë§¤ë„ êµ¬ê°„(30 ì´í•˜)ì´ê³ , "
                                         "ë³¼ë¦°ì € ë°´ë“œ í•˜ë‹¨ì„ ì°ê³  ë°˜ë“±í•˜ë ¤ëŠ” ì‹ í˜¸ê°€ í¬ì°©ë˜ì—ˆìŠµë‹ˆë‹¤. "
                                         "ê¸°ìˆ ì  ë°˜ë“±ì„ ë…¸ë¦¬ê³  ì§„ì…í•©ë‹ˆë‹¤."),
        "OVERSOLD_BOUNCE_SETUP": ("ğŸ“‰ ê³¼ë§¤ë„ êµ¬ê°„(Oversold)ì—ì„œ ë°˜ë“±í•  ìˆ˜ ìˆëŠ” íŒ¨í„´"
                                  "(Wìí˜•, ê¼¬ë¦¬ ë‹¬ë¦° ìº”ë“¤ ë“±)ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. "
                                  "ì €ì  ë§¤ìˆ˜ ê¸°íšŒë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤."),
        "RISK_MANAGEMENT": ("ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì°¨ì›ì…ë‹ˆë‹¤. ì‹œì¥ì˜ ë¶ˆí™•ì‹¤ì„±ì´ ì»¤ì§€ê±°ë‚˜, "
                            "ê¸‰ê²©í•œ ë³€ë™ì´ ì˜ˆìƒë˜ì–´ ì„ ì œì ìœ¼ë¡œ í˜„ê¸ˆì„ í™•ë³´í•©ë‹ˆë‹¤.")
    }

    msg_parts = []
    for part in code.split('|'):
        part = part.strip()
        msg_parts.append(f"<li>{mapping.get(part, part)}</li>")

    explanation =f"<ul class='list-disc pl-5 space-y-1 mt-1'>{''.join(msg_parts)}</ul>"

    log_entry['reason_mapped'] = explanation
    return log_entry


def build_trade_page(output_dir, context):
    """Builds the dedicated trading status page."""

    # Process logs to map reasons
    if context.get('trade') and 'recent_trades' in context['trade']:
        # Create a copy/map to avoid modifying original if needed, but here modifying in place is fine or map
        # map_reason_code modifies dict in place and returns it
        context['trade']['recent_trades'] = [
            map_reason_code(log_item) for log_item in context['trade']['recent_trades']
        ]

    # Group trades by ticker
    grouped_trades = {}
    if context.get('trade') and 'recent_trades' in context['trade']:
        for log_entry in context['trade']['recent_trades']:
            ticker = log_entry.get('ticker', 'Unknown')
            if ticker not in grouped_trades:
                grouped_trades[ticker] = []
            grouped_trades[ticker].append(log_entry)

    context['grouped_trades'] = grouped_trades

    env = Environment(loader=FileSystemLoader(str(TEMPLATES_DIR)))
    template = env.get_template('trade.html')
    output = template.render(context)

    with open(output_dir / 'trade.html', 'w', encoding='utf-8') as f:
        f.write(output)
    log.info("[OK] Built trade.html")


def build(output_dir=None):
    """Main build function."""
    if output_dir is None:
        output_dir = DOCS_DIR
    else:
        output_dir = Path(output_dir)

    output_dir.mkdir(parents=True, exist_ok=True)

    # 1. Load Data
    news_data = load_latest_news()
    recent_news = load_recent_news_list()  # Fetch sidebar list
    trade_data = load_trade_status()

    context = {
        'news': news_data,
        'recent_news': recent_news,  # Pass to template
        'trade': trade_data,
        'generated_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'summary_html': markdown.markdown(news_data.get('web_report', '')) if news_data else None,
        'coin_names': {
            "KRW-BTC": "ë¹„íŠ¸ì½”ì¸",
            "KRW-ETH": "ì´ë”ë¦¬ì›€",
            "KRW-XRP": "ë¦¬í”Œ",
            "KRW-SOL": "ì†”ë¼ë‚˜",
            "KRW-AVAX": "ì•„ë°œë€ì²´",
            "KRW-DOGE": "ë„ì§€ì½”ì¸"
        }
    }

    # 2. Render Dashboard (index.html)
    env = Environment(loader=FileSystemLoader(str(TEMPLATES_DIR)))
    template = env.get_template('dashboard.html')
    output_html = template.render(context)

    with open(output_dir / 'index.html', 'w', encoding='utf-8') as f:
        f.write(output_html)
    log.info(f"[OK] Built index.html at {output_dir}")

    # 3. Render Trade Page
    if trade_data:
        build_trade_page(output_dir, context)

    # 4. Copy Static Files
    if STATIC_DIR.exists():
        static_dst = output_dir / 'static'
        if static_dst.exists():
            shutil.rmtree(static_dst)
        shutil.copytree(STATIC_DIR, static_dst)
        log.info(f"[OK] Static files copied to {static_dst}")
